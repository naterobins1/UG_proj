### Binary Classification to train ML program, using the simulations generated by simulate_mark2.sh
 
# imports

import os 
import gzip
#import _pickle as pickle
import pickle

import numpy as np
from numpy import newaxis
import scipy.stats

import skimage.transform
from keras import models, layers, activations, optimizers, regularizers
from keras.utils import plot_model
from keras.models import load_model
from keras import backend as K

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
#import pymc3 # this will be removed
import pydot # optional
from sklearn import svm, datasets
from sklearn.model_selection import train_test_split
from sklearn.utils.multiclass import unique_labels

import itertools

import sys

exec(open('/home/nathanrobins/UG_proj/ImaGene/ImaGene.py').read())
#execfile('/home/nathanrobins/UG_proj/ImaGene/ImaGene.py')

#exec(open('/home/nathanrobins/UG_proj/code/confusion_mat.py').read())
#exec(open('/home/nathanrobins/UG_proj/code/Plot_Confusion_Matrix.py').read())

i = 1
#initialise variables to store loss etc
loss = []
val_loss = []
acc = []
val_acc = []

#create a while loop to iterate over everything
while i<=10:
	print(i)
	#read simulations & convert them into objects
	myfile = ImaFile(simulations_folder='/home/nathanrobins/UG_proj/code/simulation.Binary.'+str(i), nr_samples=128, model_name='Marth-3epoch-CEU')
	mygene = myfile.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=5000)
	print(myfile)
	mygene.summary()

	if i ==1:
				#check the sample allele freq for selected allele
		freqs = calculate_allele_frequency(mygene, 0.02)
		#plt.scatter(mygene.targets, freqs, marker='o')
		#plt.xlabel('Selection coeffecient')
		#plt.ylabel('Allele Freq')	

		#plt.savefig('/home/nathanrobins/UG_proj/plots/Binary/allele_freq.png)')
		#plt.show()
		#clear the plot to show next plot	
		#plt.clf()

	#manipulate the object
	#mygene.majorminor()
	mygene.filter_freq(0.01)
	mygene.sort('rows_freq')
	mygene.sort('cols_freq')
	mygene.resize((128, 128))
	mygene.convert()
	#mygene.convert()

	# choose classes of selection
	mygene.classes = np.array([0,300])

	#plot one image/class 
	#plot only once, on first iteration
	if i ==1:
		for sel in mygene.classes:
			print(sel)
			#mygene.plot(np.where(mygene.targets == sel)[0][0])

		mygene.summary()


	#vectorise targets so that they are suitable for keras
#	mygene.targets = to_binary(mygene.targets)
#####  when you to_binary before shuffling etc, the accuracy & val_accuracy = 100

	#check new dimensions
	classes_idx = get_index_classes(mygene.targets, mygene.classes)
	mygene.subset(classes_idx)

	#randomly shuffle images
	rnd_idx = get_index_random(mygene)
	mygene.subset(rnd_idx)
	

	#vectorise targets so that they are suitable for keras
	mygene.targets = to_binary(mygene.targets)

	#save & load
	#mygene.save(file='mygene')
	#mygene = load_imagene(file='mygene')



	#first iteration
	if i ==1: 
	# Build the keras model
		model = models.Sequential([
                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=mygene.data.shape[1:4]),
                    layers.MaxPooling2D(pool_size=(2,2)),
                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),
                    layers.MaxPooling2D(pool_size=(2,2)),
                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),
                    layers.MaxPooling2D(pool_size=(2,2)),
                    layers.Flatten(),
                    layers.Dense(units=64, activation='relu'),
                    layers.Dense(units=1, activation='sigmoid')])

		model.compile(optimizer='rmsprop',
			  loss='binary_crossentropy',
			  metrics=['accuracy'])   

	# intialise the network object
		mynet = ImaNet(name='[C32+P]x3+D64')

	#visualise the model
		model.summary()
#		plot_model(model, 'net.png')		
	



	#train the model
	if i <10:
		score = model.fit(mygene.data, mygene.targets, batch_size=32, epochs=20, verbose=1, validation_split=0.10)
		#update score
		mynet.update_scores(score)
		loss.extend(score.history['loss'])
		val_loss.extend(score.history['val_loss'])
		acc.extend(score.history['acc'])
		val_acc.extend(score.history['val_acc'])

#########  AMEND THE PLOTTING

	#test the model
	else:
		### write a code to concentate the plots 
		#mynet.plot_train(file='/home/nathanrobins/UG_proj/plots/Binary/training..test1.png')
		#mynet.plot_train()

		epoch = list(range(1, len(acc) +1))
		plt.figure()

		plt.subplot(211)

		plt.plot(epoch, loss, 'bo', label='Training loss')
		plt.plot(epoch, val_loss, 'b', label='Validation loss')
		plt.title('Training and validation loss')
		plt.xlabel('Epochs')
		plt.ylabel('Loss')
		plt.legend()

		plt.subplot(212)

		plt.plot(epoch, acc, 'bo', label='Training acc')
		plt.plot(epoch, val_acc, 'b', label='Validation acc')
		plt.title('Training and validation accuracy')
		plt.xlabel('Epochs')
		plt.ylabel('Accuracy')
		plt.legend()
		
		plt.tight_layout()

		plt.show()

		mynet.test = model.evaluate(mygene.data, mygene.targets, batch_size=None, verbose=1)
		#mynet.test = model.evaluate(mygene.data, batch_size=None, verbose=1)
		print(mynet.test)
		mynet.predict(mygene, model)

        # plot a confusion matrix
		print(mynet.values)

		#mynet.plot_cm(mygene.classes, file='/home/nathanrobins/UG_proj/plots/Binary/confusion_matrix..test1.png')
		mynet.plot_cm(mygene.classes)
		#plot_confusion_matrix(mynet.values[0,:], mynet.values[1,:],mygene.classes)
		#plt.show()
		#print(mynet)



	i +=1


mytest = np.load('/home/nathanrobins/UG_proj/NumpyData/CEU#2.npy')

mytest = mytest[newaxis, :, :, :]

result = model.predict(mytest)
print(result)

# WRITE A CODE TO SAVE FINAL MODEL, TESTING DATA & NETWORK) ### Binary Classification to train ML program, using the simulations generated by simulate_mark2.sh
